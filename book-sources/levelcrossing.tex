\documentclass[stochastic-or.tex]{subfiles}
\input{header}
\begin{document}

\section{Level Crossing and Balance Equations}
\label{sec:level-cross-balance}

Consider a sample path of $L:=\{\L(t) : t\geq 0\}$ of a queueing or inventory system in which jobs or items arrive and depart one by one.
We say that the sample path \recall{up-crosses level~$n$} at time~$t$ when the number of jobs in the system changes from~$n$ to $n+1$ due to an arrival, in other words, when $L(t-)=n$ and $L(t)=n+1$.
The sample path \recall{down-crosses level~$n$} at time~$t$ when, due to a departure, $L(t-)=n+1$ and $L(t)=n$.
Clearly, the number of up-crossings and down-crossings cannot differ by more than 1 at any time, because it is only possible to down-cross level~$n$ after an up-crossing (or the other way around).
This simple idea will prove to be a key stepping stone in the analysis of many stochastic systems.

In this section we make a distinction between jobs that just arrive and jobs that do enter, because we want our arguments to apply to a queueing systems in which jobs can be blocked or do not enter for other reasons.\sidenote{For inventory systems, blocked jobs are lost demands.}
Just as in~\cref{sec:rate-stability}, we write $A(t)$ and $\tilde A(t)$ to distinguish between the counting functions.


\newthought{Similar to the} definition for $A(n,t)$ in~\cref{eq:rates_}, let
\begin{align}\label{eq:102}
 \tilde A(n,t) &:=  \sum_{k=1}^{A(t)} \1{L(A_k-) = n}\1{\L(A_k) = n+1}, &
\tilde \lambda(n) &:= \lim_{t\to\times} \frac{\tilde A(n,t)}{Y(n,t)},
 \end{align}
 so that $\tilde A(n,t)$ denotes the number of jobs that \emph{enter} the system when the system contains~$n$ jobs just before arrival and
$\tilde \lambda$  the rate at which jobs enter when the system contains~$n$ jobs.
Likewise, let\sidenote{Note that we write $L(D_{k})$ and not $L(D_{k}-)$: to leave~$n$ jobs behind, the system must contain $n+1$ jobs just prior to the departure.}
\begin{align}
 D(n,t) &:=  \sum_{k=1}^{D(t)} \1{\L(D_k) = n}, & \mu(n+1) := \lim_{t\to\infty} \frac{D(n,t)}{Y(n+1,t)},
 \end{align}
denote the number of departures up to time~$t$ that\emph{ leave~$n$ customers behind}, and the departure rate from state $n+1$.


\begin{theorem}[Level-crossing]
When  jobs arrive and depart as single units,
\begin{equation}\label{eq:12}
\tilde \lambda(n) p(n) = \mu(n+1)p(n+1).
\end{equation}
\end{theorem}
\begin{proof}
By the assumption, $|L(t) - L(t-)| \leq 1$ for all $t\geq 0$.
But this implies that\sidenote{Think about this. This is simple, but has profound consequences. Do you understand why this does not need to hold for $A(n,t)$?}
\begin{equation}\label{eq:97}
|\tilde A(n,t) - D(n,t)| \leq 1.
\end{equation}
From this observation it follows immediately that
\begin{equation}\label{eq:15}
 \lim_{t\to\infty} \frac{\tilde A(n,t)}t = \lim_{t\to\infty} \frac{D(n,t)}t.
\end{equation}
But
\begin{align*}
\lim_{t\to\infty} \frac{\tilde A(n,t)}t &= \lim_{t\to\infty} \frac{\tilde A(n,t)}{Y(n,t)}\frac{Y(n,t)}t = \tilde \lambda(n) p(n),\\
\lim_{t\to\infty} \frac{D(n,t)}t &= \lim_{t\to\infty} \frac{D(n,t)}{Y(n+1,t)}\frac{Y(n+1,t)}t = \mu(n+1) p(n+1),
\end{align*}
from which claim follows.

\end{proof}

\begin{marginfigure}%[th]
\begin{tikzpicture}[scale=0.8,->,>=stealth',shorten >=1pt,auto,node distance=1.8cm,
 semithick]
 \node[state] (0) {$p(0)$} ;
 \node[state] (1) [right of=0] {$p(1)$};
 \node[state] (2) [right of=1] {$p(2)$};
% \node[state] (3) [right of=2] {}; %{$p(3)$};
% \node[state] (4) [right of=3] {$\cdots$};

\path
 (0) edge [bend left] node {$\lambda(0)$} (1)
 (1) edge [bend left] node {$\mu(1)$} (0)
 (1) edge [bend left] node {$\lambda(1)$} (2)
 (2) edge [bend left] node {$\mu(2)$} (1);
% (2) edge [bend left] node {$\lambda(2)$} (3)
% (3) edge [bend left] node {$\mu(3)$} (2)
% (3) edge [bend left] node {$\lambda(3)$} (4)
% (4) edge [bend left] node {$\mu(4)$} (3);

%\draw[-, dotted, gray] (1.5,-1.5)--(1.5,1.5) node[above, black] {}; % {level~$1$};
\draw[->] (3,1.8) node[left] {$\tilde A(1,t)$} -- (4.5,1.8);
\draw[<-] (3,-1.8) node[left] {$D(1,t)$} --(4.5,-1.8) ;

\end{tikzpicture}
\end{marginfigure}


\newthought{Suppose we can} specify\sidenote{In \cref{sec:mm1} and onward we will model many queueing situations by making suitable choices for $\tilde \lambda(n)$ and $\mu(n)$.}
the arrival and service rates $\tilde \lambda(n)$ and $\mu(n)$, then we can easily compute the long-run fraction of time $p(n)$ that the system contains~$n$ jobs.
To see this, rewrite~\cref{eq:12} as
\begin{equation}\label{eq:25}
 p(n+1) = \frac{\tilde \lambda(n)}{\mu(n+1)}p(n).
\end{equation}
A straightaway recursion then leads to
\begin{equation*}
 p(n+1) = \frac{\tilde \lambda(n)\tilde\lambda(n-1)\cdots \tilde \lambda(0)}{\mu(n+1)\mu(n)\cdots \mu(1)}p(0).
\end{equation*}
Thus, $p(n)$, $n\geq 1$, is just $p(0)$ times a constant, and this constant is based on  arrival and service rates.

To determine $p(0)$ we can use the fact that the numbers $p(n)$ represent probabilities.
Hence, from the normalizing condition $\sum_{n=0}^\infty p(n)=1$, we get $p(0) = G^{-1}$ with
$G$ being the \emph{normalization constant}
\begin{equation*}
G = 1+\sum_{n=0}^\infty \frac{\tilde \lambda(n)\tilde \lambda(n-1)\cdots\tilde \lambda(0)}{\mu(n+1)\mu(n)\cdots \mu(1)}.
\end{equation*}

Finally, once we have $p(n)$, it is easy to compute  the time-average\sidenote{It is important to realize that this is not necessarily the same as what jobs see upon arrival.} number of jobs in the system and the long-run fraction of time the system contains at least~$n$:
\begin{align*}
\E\L &= \sum_{n=0}^\infty n p(n), & \P{\L \geq n} &= \sum_{i=n}^\infty p(i).
\end{align*}


\newthought{With the definitions} of $A(n,t)$ and $D(n,t)$, we can  establish a nice relation between $\pi(n)$ and $\delta(n)$, i.e.,  statistics as obtained by the departures. Define, analogous to $\pi(n)$,
\begin{equation*}
 \delta(n) := \lim_{t\to\infty} \frac{D(n,t)}{D(t)}
\end{equation*}
as the long-run fraction of jobs that leave~$n$ jobs \emph{behind}.
From~\cref{eq:15} and supposing that $A(n,t) = \tilde A(n,t)$,
\begin{equation*}
\frac{A(t)}t \frac{A(n,t)}{A(t)} = \frac{A(n,t)}t = \frac{\tilde A(n,t)}{t}\approx \frac{D(n,t)}t
= \frac{D(t)}t \frac{D(n,t)}{D(t)}.
\end{equation*}
Taking limits at the left and right, and using~\cref{eq:28}, we obtain for the $G/G/c$ queue\sidenote{Because customers arrive and leave as single units in a (rate-stable) $G/G/c$ queue.}
\begin{equation} \label{eq:36}
 \lambda \pi(n) = \delta \delta(n).
\end{equation}
Consequently, for the (stable)  $G/G/c$ queue  the statistics obtained by arrivals is the same as statistics obtained by departures, i.e.,
\begin{equation} \label{eq:39}
\lambda = \delta \iff \pi(n) = \delta(n).
\end{equation}


\newthought{It is important} to realize that the level-crossing argument cannot always be used, as it is not always possible to split the state space into two disjoint parts by `drawing a line' between two states.
For a more general approach, we focus on a single state and count how often this state is entered and left.
\begin{marginfigure}
\begin{tikzpicture}[scale=0.8,->,>=stealth',shorten >=1pt,auto,node distance=1.8cm,
 semithick]
% \node[state] (0) {$p(0)$} ;
 \node[state] (1) [right of=0] {$p(1)$};
 \node[state] (2) [right of=1] {$p(2)$};
 \node[state] (3) [right of=2] {$p(3)$};
% \node[state] (4) [right of=3] {$\cdots$};

\draw[dashed] (3.4,-1.8) rectangle (5.6,1.8);

\path
% (0) edge [bend left] node {$\lambda(0)$} (1)
% (1) edge [bend left] node {$\mu(1)$} (0)
 (1) edge [bend left] node[fill=white] {$\lambda(1)$} (2)
 (2) edge [bend left] node[fill=white] {$\mu(2)$} (1)
 (2) edge [bend left] node[fill=white] {$\lambda(2)$} (3)
 (3) edge [bend left] node[fill=white] {$\mu(3)$} (2);
 % (3) edge [bend left] node[above] {$\lambda(3)$} (4)
 % (4) edge [bend left] node[below] {$\mu(4)$} (3);
\end{tikzpicture}
\end{marginfigure}
Specifically, define $I(n,t) = A(n-1,t) + D(n,t)$ as the number of times the queueing process enters state~$n$ either due to an arrival from state $n-1$ or due to a departure leaving~$n$ jobs behind. Similarly,  $O(n,t) = A(n,t) + D(n-1,t)$ counts how often state~$n$ is left either by an arrival (to state $n+1$) or a departure (to state $n-1$).


Just like~\cref{eq:97}, it is evident that $|I(n,t)-O(n,t)|\leq 1$, and this implies\sidenote{~\cref{ex:79}}
\begin{equation}\label{eq:104}
 \lambda(n-1)p(n-1)+\mu(n+1)p(n+1) = (\lambda(n)+\mu(n))p(n).
\end{equation}
These equations hold for any $n\geq 1$ and are known as the \recall{balance equations}.
We will use these equations later in the book to analyze queueing networks.


\newthought{Level crossing arguments can} also be applied to continuous systems.
With this we can find a closed form expression for the waiting time of the $M/G/1$ queue.
However, this is a bit more complicated as the argument hinges on an integral equation.
If you don't like developing mathematical skills, you may skip this derivation.

Suppose that the waiting time~$W$ of the $M/G/1$ queue has a density~$f$, that is, the cdf $F(x) = \P{W\leq x}$ has a derivative $f(x)$ for all $x>0$.\sidenote{For a real proof we should prove first that~$f$ exists.}
($F$ is only differentiable from the right at~$0$ because $\P{W=0}>0$, while $\P{W\leq x} = 0$ for $x<0$.)
Consider some level $x>0$.
By PASTA, the rate of arriving jobs that see a waiting time $y \in [0, x)$ is equal to $\lambda f(y)$. (Observe that we use the splitting property of Poisson processes.)
To up-cross level~$x$ from state $y< x$, the service time must be at least $x-y$, the probability of which is $G(x-y) = \P{S>x-y}$.
Adding up the rates for all possible waiting times below~$x$ gives that $\lambda\int_0^x f(y) G(x-y)\d y$ is the up-crossing rate of level~$x$.
The downcrossing rate is $f(x)$ because a fraction $f(x)$ of waiting time is served per unit time at level~$x$.
Equaling these rates gives the integral equation $\lambda \int_0^{x} f(y) G(x-y)\d y = f(x)$.
For $x=0$, we need to consider the atom $\P{W=0}$.
In that case, $\lambda \P{W=0} = f(0+)$.
We can combine all this in the following level crossing equation
\begin{equation*}
\lambda\int_0^x G(x-y) \d F(y) = f(x).
\end{equation*}

Using this integral equation,
\begin{align*}
  \E W
  &=    \int_0^{\infty} x f(x) \d x
  = \lambda \int_0^{\infty} x \int_0^{x} G(x-y) \d F(y) \d x= \\
%  &= \lambda \int_0^{\infty} \int_0^{\infty} x \1{y \leq x} G(x-y) \d F(y)\d x  \\
  &= \lambda \int_0^{\infty} \int_0^{\infty} x \1{y \leq x} G(x-y) \d x \d F(y) \\
  &= \lambda \int_0^{\infty} \int_0^{\infty} (u+y) G(u) \d u \d F(y) \\
  &= \lambda \int_0^{\infty} (\E{S^2}/2 + y \E S) \d F(y) \\
  &= \lambda \E{S^2}/2 + \lambda \E S \E W. % = \lambda \E{S^2}/2 + \rho \E W.
\end{align*}
Bringing $\lambda \E S \E W = \rho \E W$ to the left, and dividing by $1-\rho$ gives
\begin{align*}
  \E W  &= \lambda \frac{\E{S^2}}{2(1-\rho)}.
\end{align*}
It is left to compute the second moment of the service time~$S$. We will derive this formula with the renewal reward equation in~\cref{sec:n-policies-mg1}.

As a last point of interest, let's derive the density of the waiting time for the $M/M/1$ queue.
As $S\sim \Exp{\mu}$ in this case, $f$ must satisfy $f(x) =  \lambda \int_0^x  e^{-(x-y)\mu} \,\d F(y)$.
Multiplying both sides by $e^{\mu x}$ and defining $g(x) = e^{\mu x} f(x)$ this can be rewritten to
$g(x) = \lambda \int_0^x g(y) \,\d F(y)$.
Differentiating the LHS and RHS wrt $x$ gives the differential equation $g'(x) = \lambda g(x)$. Hence, $g(x) = A e^{\lambda x}$, hence,
$f(x) = A e^{-(\mu-\lambda)x}$.  At $x=0$, we have that $f(0) = \lambda p(0)$.
Since $p(0)=1-\rho$, it follows that
\begin{equation}\label{eq:l22}
f(x) = \lambda(1-\rho) e^{- \mu(1-\rho)x}, \quad x > 0.
\end{equation}

Another fun way to obtain this result is to use conditioning on the number $L_Q$ of jobs found in queue at arrival, and then using that the total service of these $L_Q$ customers have a gamma density. Here is the first step of the derivation:

\begin{align*}
f(x)
&= \sum_{k=1}^\infty \P{W = x | L_Q = k}\P{L_Q = k } \\
&= \sum_{k=1}^\infty \P{S_1 + S_2 + \cdots + S_k = x}\P{L_Q = k }.
% &= (1-\rho) \sum_{k=1}^\infty \rho^k \P{S_1 + S_2 + \cdots + S_k = x } \\
% &= (1-\rho) \sum_{k=1}^\infty \rho^k \mu \frac{(\mu x)^{k-1}}{(k-1)!}e^{-\mu x}\\
% &= (1-\rho) \mu \rho \sum_{k=1}^\infty \rho^{k-1} \frac{(\mu x)^{k-1}}{(k-1)!}e^{-\mu x}\\
% &= (1-\rho) \lambda e^{-\mu x}\sum_{k=0}^\infty \rho^{k} \frac{(\mu x)^{k}}{k)!}\\
% &= (1-\rho) \lambda e^{-\mu x}\sum_{k=0}^\infty \frac{(\rho \mu x)^{k}}{k)!}\\
% &= (1-\rho) \lambda e^{-\mu x} e^{\rho \mu x}\\
% &= (1-\rho) \lambda e^{-\mu (1-\rho)x}
\end{align*}
Substituting the Gamma distribution and some algebra leads also to~\cref{eq:l22}.

\begin{truefalse}
At a large hotel, taxi cabs arrive at a rate of 15 per
hour, and parties of riders arrive at the rate of 12 per
hour. Whenever taxicabs are waiting, riders are served immediately
upon arrival. Whenever riders are waiting, taxicabs are loaded
immediately upon arrival. A maximum of three cabs can wait at a time (other cabs must go elsewhere). Let $p(i,j)$ be the steady-state probability of there being $i$ parties of riders and $j$ taxicabs waiting at the hotel. Claim: the transitions are modeled by the graph below.

 \begin{center}

\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.8cm,
 semithick]
 \node[state] (0) {$p(0,3)$} ;
 \node[state] (1) [right of=0] {$p(0,2)$};
 \node[state] (2) [right of=1] {$p(0,1)$};
 \node[state] (3) [right of=2] {$p(0,0)$};
 \node[state] (4) [right of=3] {$p(1,0)$};
 \node[state] (5) [right of=4] {$p(2,0)$};
 \node[state] (6) [right of=5] {$p(\cdot, 0)$};

\path
 (0) edge [bend left] node {$\lambda$} (1)
 (1) edge [bend left] node {$\mu$} (0)
 (1) edge [bend left] node {$\lambda$} (2)
 (2) edge [bend left] node {$\mu$} (1)
 (2) edge [bend left] node {$\lambda$} (3)
 (3) edge [bend left] node {$\mu$} (2)
 (3) edge [bend left] node {$\lambda$} (4)
 (4) edge [bend left] node {$\mu$} (3)
 (4) edge [bend left] node {$\lambda$} (5)
 (5) edge [bend left] node {$\mu$} (4)
 (5) edge [bend left] node {$\lambda$} (6)
 (6) edge [bend left] node {$\mu$} (5)
;
\end{tikzpicture}
 \end{center}
\begin{solution}
True.
\end{solution}
\end{truefalse}



\begin{truefalse}
To obtain the \emph{ balance equations} we do not count the number of up- and down crossings of a level. Instead we count how often a box around a state, such as state $2$ in the figure below, is crossed from inside and outside.

\begin{center}
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.8cm,
 semithick]
 \node[state] (0) {$p(0)$} ;
 \node[state] (1) [right of=0] {$p(1)$};
 \node[state] (2) [right of=1] {$p(2)$};
 \node[state] (3) [right of=2] {$p(3)$};
 \node[state] (4) [right of=3] {$\cdots$};

\draw[dashed] (2.6,-1.2) rectangle (4.5,1.2);

\path
 (0) edge [bend left] node {$\lambda(0)$} (1)
 (1) edge [bend left] node {$\mu(1)$} (0)
 (1) edge [bend left] node[fill=white] {$\lambda(1)$} (2)
 (2) edge [bend left] node[fill=white] {$\mu(2)$} (1)
 (2) edge [bend left] node[fill=white] {$\lambda(2)$} (3)
 (3) edge [bend left] node[fill=white] {$\mu(3)$} (2)
 (3) edge [bend left] node[above] {$\lambda(3)$} (4)
 (4) edge [bend left] node[below] {$\mu(4)$} (3);
\end{tikzpicture}
 \end{center}
\begin{solution}
True.
\end{solution}
\end{truefalse}

\begin{truefalse}
 Consider the $M^2/M^2/1/3$ queue. The graph below shows all relevant transitions.

 \begin{center}
\begin{tikzpicture}[scale=1,->,>=stealth',shorten >=1pt,auto,node distance=2.8cm,
 semithick]
\node[state] (0) {$0$};
\node[state] (1) [right of=0] {$1$};
\node[state] (2) [right of=1] {$2$};
\node[state] (3) [right of=2] {$3$};

\path
(0) edge [bend left] node[above] {$\lambda$} (1)
(1) edge [bend left] node[above] {$\lambda$} (2)
(2) edge [bend left] node[above] {$\lambda$} (3)
(3) edge [bend left] node[below] {$\mu$} (1)
(2) edge [bend left] node[below] {$\mu$} (0);
\end{tikzpicture}
 \end{center}
\begin{solution}
False. The figure sketches the $M/M^2/1/3$ queue.
\end{solution}
\end{truefalse}



\begin{truefalse}
For the $G/G/1$ the difference between the number of out transitions' and the number of `in transitions' is at most 1 for all $t$. As a consequence,
\begin{align*}
\text{transitions out } &\approx \text{transitions in } \iff \\
A(n,t) + D(n-1,t) &\approx A(n-1,t) + D(n,t) \iff \\
\frac{A(n,t) + D(n-1,t)}t &\approx \frac{A(n-1,t) + D(n, t)}t \iff \\
\frac{A(n,t)}t + \frac{D(n-1,t)}t &\approx \frac{A(n-1,t)}t + \frac{D(n,t)}t.
\end{align*}
Thus, under proper technical assumptions (which you can assume to be satisfied) this becomes for $t\to\infty$,
\begin{equation*}
(\lambda(n) +\mu(n))p(n) = \lambda(n-1)p(n-1) + \mu(n+1)p(n+1).
\end{equation*}
We claim that if we specialize this result for the $M/D/1$ queue we have that
$\lambda(n) = \lambda$ and $\mu(n) = \mu$, hence using PASTA,
\begin{equation*}
(\lambda +\mu)\pi(n) = \lambda\pi(n-1) + \mu\pi(n+1).
\end{equation*}
\begin{solution}
False. Since service times are constant in the $M/D/1$ queue, hence not memoryless, $\mu \neq \mu(n+1)$ for the $M/D/1$ queue.x
\end{solution}
\end{truefalse}


\begin{exercise} \label{ex:111}
Consider the following (silly) queueing process.
At times $0, 2,4, \ldots$ customers arrive, each customer requires~$1$ unit of service, and there is one server.
 \begin{enumerate}
 \item  Find an expression for $A(n,t)$, when $L(0)=0$.
 \item Show that $\pi(0)=1$ and $\pi(n)=0$, for $n>0$.
 \item Check that $\lambda \pi(n) = \lambda(n) p(n)$.
 \item  Find an expression for $Y(n,t)$.
 \item Compute $p(n)$ and $\lambda(n)$.
 \item Compute $D(n,t)$ and $\mu(n+1)$ for $n\geq 0$.
 \item Compute $\lambda(n) p(n)$ for $n\geq 0$, and check $\lambda(n) p(n) = \mu(n+1) p(n+1)$.
 \end{enumerate}

\begin{solution}
\begin{enumerate}
\item $A_{k} = 2(k-1)$, $k=1, 2, \ldots$, as jobs arrive at $t=0, 2, 4, \ldots$ Thus, $A(t) = 1 + \lfloor t/2 \rfloor$ for $t \geq 0$.
(BTW, $A(t)/t \to 1/2$ as $t\to \infty$.)
We also know that $L(s)=1$ if $s\in [2k, 2k+1)$ and $L(s)=0$ for $s\in[2k-1, 2k)$ for $k=0, 1, 2, \ldots$.
Thus, $L(A_k-) = L(2k-)=0$.
Therefore, $A(0,t) = A(t)$ for $t \geq 0$, and $A(n,t)=0$ for $n\geq 1$.
\item All arrivals see an empty system.
  Hence, $A(0,t)/A(t) \approx (t/2)/(t/2) = 1$, and $A(n,t)=0$ for $n>0$.
  Thus, $\pi(0) = \lim_{t\to\infty} A(0,t)/A(t) = 1$ and $\pi(n)=0$ for $n>0$.
  Recall from the other exercises that $p(0)=1/2$.
  Hence, statistics as obtained via time averages are not necessarily the same as statistics obtained at arrival moments (or any other point process).
  \item $\lambda = \lim_{t\to\infty} A(t)/t = 1/2$. $\lambda(0)=1$, $p(0)=1/2$, and $\pi(0)=1$. Hence,
\begin{equation*}
 \lambda \pi(0) = \lambda(0) p(0) \implies \frac 1 2 \times 1 = 1\times \frac 1 2.
\end{equation*}
For $n>0$ it's easy, everything is 0.
\item
Observe that the system never contains
 more than 1 job. Hence, $Y(n,t)=0$ for all $n\geq 2$. Then we see that
 $Y(1,t) = \int_0^t \1{\L(s) = 1}\d s$. Now observe that for our
 queueing system $L(s)=1$ for $s\in[0,1)$, $L(s)=0$ for
 $s\in[1,2)$, $L(s)=1$ for $s\in[2,3)$, and so on. Thus, when
 $t<1$, $Y(1,t)=\int_0^t \1{\L(s)=1} \d s = \int_0^t 1\d s = t$.
 When $t\in[1,2)$,
 \begin{equation*}
 L(t)=0 \implies \1{\L(t)=0} \implies Y(1,t) \text{ does not change}.
 \end{equation*}
Continuing to $[2,3)$ and so on gives
 \begin{equation*}
 Y(1,t) =
 \begin{cases}
 t & t\in[0,1), \\
 1 & t\in[1,2), \\
 1+(t-2) & t\in[2,3), \\
 2+(t-4) & t\in[4,5),
 \end{cases}
 \end{equation*}
 and so on. With this, we see that the general formula must be
 \begin{equation*}
Y(t,1) =
 \begin{cases}
1+ \lfloor t/2\rfloor +   t-\lfloor t \rfloor, &\text{if } \lfloor t \rfloor \text{ is even}, \\
1+ \lfloor t/2\rfloor, &\text{if } \lfloor t \rfloor \text{ is odd}.
 \end{cases}
 \end{equation*}

Since $Y(n,t)=0$ for all $n\geq 2$, $L(s) = 1$ or
 $L(s)=0$ for all~$s$, therefore,
 \begin{equation*}
 Y(0,t) = t-Y(1,t).
 \end{equation*}
 \item
 \begin{align*}
 \lambda(0) &\approx \frac{A(0,t)}{Y(0,t)} \approx \frac{t/2}{t/2} = 1, \\
 \lambda(1) &\approx \frac{A(1,t)}{Y(1,t)} \approx \frac{0}{t/2} = 0, \\
 p(0) &\approx \frac{Y(0,t)}{t} \approx \frac{t/2}{t} = \frac 1 2, \\
 p(1) &\approx \frac{Y(1,t)}{t} \approx \frac{t/2}{t} = \frac 1 2.
 \end{align*}
For the rest $\lambda(n) = 0$, and $p(n)=0$, for $n\geq 2$.
\item
 $D(0,t) = \sum_{k=1}^\infty\1{D_k\leq t, L(D_k)=0}$. From the graph of $\{\L(s)\}$ we see that all jobs leave an empty system behind. Thus, $D(0,t) \approx t/2$, and $D(n,t)=0$ for $n\geq 1$. With this, $D(0,t)/Y(1,t) \sim (t/2)/(t/2) = 1$, and so,
 \begin{equation*}
 \mu(1) = \lim_{t\to\infty} \frac{D(0,t)}{Y(1, t)} = 1,
 \end{equation*}
and $\mu(n) = 0$ for $n\geq2$.
\item
 $\lambda(0)p(0)=1\cdot 1/2 = 1/2$, $\lambda(n)p(n)= 0$ for $n>1$, as $\lambda(n)=0$ for $n>0$.
Next, $\mu(1)=1$, hence $\mu(1) p(1) = 1\cdot 1/2 = 1/2$. Moreover, $\mu(n)=0$ for $n\geq 2$.
Clearly, for all~$n$ we have $\lambda(n)p(n)= \mu(n+1)p(n+1)$.
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise}\label{ex:l-111}
 Derive $\E\L = \sum_{n=0}^\infty n p(n)$ from~\cref{eq:46}.
\begin{solution}
Noting that %As $L(s)$ counts the number of jobs in the system at time~$s$ (thus $L(s)$ is an integer),
$L(s) = \sum_{n=0}^\infty n\, \1{\L(s) = n}$, we see that
%With this we can write for the time-average number of jobs in the system
\begin{equation*}
\frac 1 t \int_0^t L(s) \d s = \frac 1 t \int_0^t \left(\sum_{n=0}^{\infty} n\, \1{\L(s) = n}\right) \d s
= \sum_{n=0}^{\infty} \frac n t \int_0^t \1{\L(s) = n} \d s.
\end{equation*}
Now apply~\cref{eq:18}.
\end{solution}
\end{exercise}







\begin{exercise}\label{ex:28}
Show for the $M/G/1$  that  with probability~$\rho$ a job leaves behind a busy server.
\begin{hint}
 Apply PASTA and \cref{eq:39}.
\end{hint}
\begin{solution}
$\rho = \sum_{i=1}^\infty p(i) = \sum_{i=1}^\infty \pi(i) = \sum_{i=1}^\infty \delta(i)$.
\end{solution}
\end{exercise}


\begin{exercise}\label{ex:67}
Consider a single server that serves one queue and serves only in batches of 2 jobs at a time (so never 1 job or more than 2 jobs).
At most 3 jobs fit in the system.
Single jobs arrive as a Poisson process with $\lambda$.
Due to blocking, we take $\lambda(n) = \lambda$ for $n<3$ and $\lambda(n)=0$ for $n\geq 3$.
The batch service times are exponentially distributed with mean $1/\mu$, so that by the memoryless property, $\mu(n) = \mu$.

Make a graph of the state-space and show, with arrows, the transitions that can occur and  use level-crossing arguments to express the steady-state probabilities $p(n), n=0,\ldots, 3$ in terms of $\lambda$ and $\mu$.
\begin{solution}
%It is the $M/M^2/1/3$ queue.

\begin{tikzpicture}[scale=1,->,>=stealth',shorten >=1pt,auto,node distance=2.8cm,
 semithick]
\node[state] (0) {$0$};
\node[state] (1) [right of=0] {$1$};
\node[state] (2) [right of=1] {$2$};
\node[state] (3) [right of=2] {$3$};

\path
(0) edge [bend left] node[above] {$\lambda$} (1)
(1) edge [bend left] node[above] {$\lambda$} (2)
(2) edge [bend left] node[above] {$\lambda$} (3)
(3) edge [bend left] node[below] {$\mu$} (1)
(2) edge [bend left] node[below] {$\mu$} (0);

\draw[-, dotted, gray] (4,-2.)--(4,2.0) node[above, black] {level~$1$};
\end{tikzpicture}

With level-crossing:
 \begin{align*}
 \lambda p(0) &= \mu p(2), \quad\text{the level between 0 and 1,}\\
 \lambda p(1) &= \mu p(2) +\mu p(3), \quad\text{see level 1,}\\
 \lambda p(2) &= \mu p(3), \quad\text{the level between 2 and 3.}\\
 \end{align*}
 Solving this in terms of $p(0)$ gives $p(2) = \rho p(0)$, $p(3) = \rho p(2) = \rho^2p(0)$, and
 \begin{equation*}
 \lambda p(1) = \mu(p(2) + p(3)) = \mu (\rho + \rho^2) p(0) = (\lambda + \lambda^2/\mu) p(0),
 \end{equation*}
hence $p(1) = p(0)(\mu + \lambda)/\mu$.
\end{solution}
\end{exercise}

\begin{exercise}\label{ex:79}
Show \cref{eq:104} from  $|I(n,t)-O(n,t)|\leq 1$.
\begin{solution}
\begin{equation*}
\lim_{t\to\infty} \frac{I(n,t)}t = \lim_{t\to\infty} \frac{A(n-1,t)}t + \lim_{t\to\infty} \frac{D(n,t)}t = \lambda(n-1) p(n-1) +
\mu(n+1) p(n+1)
\end{equation*}
and
\begin{equation*}
\lim_{t\to\infty} \frac{O(n,t)}t = \lim_{t\to\infty} \frac{A(n,t)}t + \lim_{t\to\infty} \frac{D(n-1,t)}t = \lambda(n) p(n) +
\mu(n) p(n)
\end{equation*}
\end{solution}
\end{exercise}

\input{trailer}
